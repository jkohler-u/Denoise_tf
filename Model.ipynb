{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#connect to colab\n",
        "!git clone https://github.com/jkohler-u/Denoise_tf.git\n",
        "import sys\n",
        "sys.path.append('/content/Denoise_tf')"
      ],
      "metadata": {
        "id": "qEJ-wLUCYXWS",
        "outputId": "3871c653-375b-416b-f048-0612728ca3db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Denoise_tf'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 59 (delta 29), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (59/59), 6.02 MiB | 2.52 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#our own pyfiles\n",
        "import preprocessing\n",
        "import unet\n",
        "import postprocessing"
      ],
      "metadata": {
        "id": "IEWP5VKXYoPg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load tensorboard\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "nYC1bkAk_Cp5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BBPfToW6UEd",
        "outputId": "c620164f-2251-4bfb-c0b2-d8148cdc4349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#working with files\n",
        "from zipfile import ZipFile\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "filename = 'a1'\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change the working directory to your Drive\n",
        "os.chdir('/content/drive/MyDrive')\n",
        "\n",
        "# Open the zipfile and extract its contents to memory\n",
        "with ZipFile('CleanSpeech_training.zip', 'r') as zip_file:\n",
        "  zip_file.extractall(filename)\n",
        "\n",
        "filename = 'a2'\n",
        "\n",
        "# Open the zipfile and extract its contents to memory\n",
        "with ZipFile('NoisySpeech_training.zip', 'r') as zip_file:\n",
        "  zip_file.extractall(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NlqymfmcATH",
        "outputId": "e59984c0-5b4b-4673-f129-756c93a7b996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7f9f62b57ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7f9f62b57b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "/content/Denoise_tf/preprocessing.py:49: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(data)\n"
          ]
        }
      ],
      "source": [
        "#creating the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "#load the data \n",
        "train_noisy = preprocessing.prepare_data('a2')\n",
        "train_clean = preprocessing.prepare_data('a1')\n",
        "train_noisy = preprocessing.make_same(train_noisy, 196500)\n",
        "train_clean = preprocessing.make_same(train_clean, 196500)\n",
        "\n",
        "# Turn all the data into complex spectrograms\n",
        "clean_spec = preprocessing.spectrogram(np.array(train_clean))\n",
        "noisy_spec = preprocessing.spectrogram(np.array(train_noisy))\n",
        "\n",
        "#convert the data into a tf dataset\n",
        "tf_dataset = tf.data.Dataset.from_tensor_slices((noisy_spec, clean_spec))\n",
        "\n",
        "# Calculate the total number of samples in the dataset\n",
        "num_samples = tf.data.experimental.cardinality(tf_dataset).numpy()\n",
        "\n",
        "# Shuffle the dataset\n",
        "tf_dataset = tf_dataset.shuffle(num_samples)\n",
        "\n",
        "#randomly split the dataset into train and test sets\n",
        "train_size = int(0.8 * num_samples)\n",
        "test_size = num_samples - train_size\n",
        "train_dataset = tf_dataset.take(train_size)\n",
        "test_dataset = tf_dataset.skip(train_size)\n",
        "\n",
        "#batch\n",
        "batch_size = 10\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6PJpM0EggAm",
        "outputId": "0262118d-0f26-4bfb-ec44-43c6db85a93c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - 65s 4s/step - loss: 0.3840 - val_loss: 0.2750\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2682"
          ]
        }
      ],
      "source": [
        "'''fit function'''\n",
        "#tf\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#added tensorboard log\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#run the model\n",
        "unet.model.fit(\n",
        "    train_dataset,\n",
        "    epochs=20,\n",
        "    shuffle=True,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=[tensorboard_callback],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eS0rD29AB3o"
      },
      "outputs": [],
      "source": [
        "# Convert tf dataset back to numpy arrays\n",
        "prediciton, noisy, clean = postprocessing.get_one_of_each(train_dataset)\n",
        "\n",
        "#prediction_for_rest = prediction_for_rest.take(1)\n",
        "pred = (unet.model.predict(prediciton.batch(1)))\n",
        "pred = tf.squeeze(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWQ2t-aRHYyk"
      },
      "outputs": [],
      "source": [
        "#plotting the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, axarr = plt.subplots(1,3, figsize=(20,4))\n",
        "axarr[0].imshow(noisy, aspect='auto', origin='lower', cmap='viridis')\n",
        "axarr[0].set_title(\"noisy\")\n",
        "axarr[1].imshow(clean, aspect='auto', origin='lower', cmap='viridis')\n",
        "axarr[1].set_title(\"clean\")\n",
        "axarr[2].imshow(pred, aspect='auto', origin='lower', cmap='viridis')\n",
        "axarr[2].set_title(\"prediction\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJX1ytilIHmC"
      },
      "outputs": [],
      "source": [
        "#displying audio\n",
        "import IPython\n",
        "import soundfile as sf\n",
        "\n",
        "#convert the spectograms back to audio\n",
        "n = postprocessing.convert_to_audio(noisy)\n",
        "c = postprocessing.convert_to_audio(clean)\n",
        "p = postprocessing.convert_to_audio(pred)\n",
        "\n",
        "#create audio files\n",
        "sr = 16000\n",
        "sf.write('noisy.wav', n, sr)\n",
        "sf.write('clean.wav', c, sr)\n",
        "sf.write('pred.wav', p, sr)\n",
        "\n",
        "#noisy audio\n",
        "IPython.display.Audio('noisy.wav')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean audio\n",
        "IPython.display.Audio('clean.wav')"
      ],
      "metadata": {
        "id": "tlnWE0hRJV3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicted audio\n",
        "IPython.display.Audio('pred.wav')"
      ],
      "metadata": {
        "id": "IetCufcHIxj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv_SqB3GJsMJ"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}